{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage.draw import polygon\n",
    "import cv2\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_images(json_dict: dict):\n",
    "    '''\n",
    "    input:\n",
    "        json_dict [dict] --> the dictionary created by function INSERT NAME from the filename.json file\n",
    "    function:\n",
    "        gets the number of images in each file\n",
    "    return:\n",
    "        returns the number of images in the json file [int]\n",
    "    interactions:\n",
    "        None yet\n",
    "    '''\n",
    "    return len(json_dict['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json(path_to_file: str):\n",
    "    '''\n",
    "    input:\n",
    "        path to json file [str] \n",
    "    function:\n",
    "        opens and stores the data as a dictionary and returns the data dictionary\n",
    "    return:\n",
    "    interactions:\n",
    "    '''\n",
    "    if os.path.isfile(path_to_file):\n",
    "        with open(path_to_file) as f:\n",
    "          data = json.load(f)\n",
    "        return data\n",
    "    else:\n",
    "        raise FileNotFoundError ('No such file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_size(json_dict: dict, image_id: int):\n",
    "    '''\n",
    "    input:\n",
    "        json_dict [dict] --> the dictionary created by function INSERT NAME from the filename.json file\n",
    "        image_id [int] --> the image_id within in json_dict that we want the data from\n",
    "    function:\n",
    "        returns the size of image give by image_id\n",
    "    return:\n",
    "        returns row [int], and col [int]\n",
    "    interactions:    \n",
    "    '''\n",
    "    col = json_dict['images'][image_id]['width']\n",
    "    row = json_dict['images'][image_id]['height']\n",
    "    return row, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_filename(json_dict: dict, image_id: int):\n",
    "    '''\n",
    "    input:\n",
    "        json_dict [dict] --> the dictionary created by function INSERT NAME from the filename.json file\n",
    "        image_id [int] --> the image_id within in json_dict that we want the data from\n",
    "    function:\n",
    "        returns the name of the seq and the filename, which indicates with image the segmentation data is attached to\n",
    "    return:\n",
    "        2 strings -- the \"seq\" name [str], the 'filename' [str]\n",
    "    interactions:    \n",
    "    '''\n",
    "    return json_dict['images'][image_id]['file_name'].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(json_dict: dict, image_id: int):\n",
    "    '''\n",
    "    input:\n",
    "        json_dict [dict] --> the dictionary created by function INSERT NAME from the filename.json file\n",
    "        image_id [int] --> the image_id within in json_dict that we want the data from\n",
    "    function:\n",
    "        get all the 'segmentations' for the given image_id\n",
    "    returns:\n",
    "        a dictionary that contains the category and the segmentation points for each object in the image\n",
    "    interactions:\n",
    "    '''\n",
    "    # lambda function that reorganize data into an array of shape [row, col]\n",
    "    reorganize = lambda x: np.array(list(zip(x[1::2], x[::2]))).squeeze().round()\n",
    "    # create a dictionary to store the segmentation data\n",
    "    # each entry would be [{category_id}, {segmentation}]\n",
    "    storage = dict()\n",
    "    \n",
    "    # create a counter to number the items in the dictionary\n",
    "    counter = 0\n",
    "    \n",
    "    # loop through the json_dict and store all the segmentation data for the given image_id\n",
    "    annotation_data = json_dict['annotations']\n",
    "    for i in range(len(annotation_data)):\n",
    "        if annotation_data[i]['image_id'] == image_id:\n",
    "            try:\n",
    "                storage[str(i)] = [{'category_id': annotation_data[i]['category_id']}, {'segmentation': reorganize(annotation_data[i]['segmentation'][0])}]\n",
    "                counter += 1\n",
    "            except KeyError:\n",
    "                storage[str(i)] = [{'category_id': 1}, {'segmentation': reorganize(annotation_data[i]['segmentation'][0])}]\n",
    "                counter += 1\n",
    "   \n",
    "    # return the dictionary\n",
    "    return storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_mask(annotations_dict: dict, image_size: tuple):\n",
    "    '''\n",
    "    input:\n",
    "        annotations_dict [dict] -- this is the output of the get_annotations() function\n",
    "        image_size [tuple] -- size of the image for the current data\n",
    "    function:\n",
    "        creates a binary mask of that same size as the original image\n",
    "    return:\n",
    "        returns the binary mask [np.array]\n",
    "    interactions:    \n",
    "    '''\n",
    "    # get the number of unique categories\n",
    "    unique_categories = [annotations_dict[idx][0]['category_id'] for idx in annotations_dict.keys()]\n",
    "    \n",
    "    # ADD SOME CODE TO WHERE FOR EACH UNIQUE CATEGORY A COLOR IS ASSIGNED -- TO BE COMPLETED -- NOT NECESSARY RIGHT NOW\n",
    "    \n",
    "    # create an empty image\n",
    "    image = np.zeros((image_size[0], image_size[1]), dtype=np.uint8)\n",
    "    \n",
    "    for idx in annotations_dict.keys():\n",
    "        polygon_idx = annotations_dict[idx][1]['segmentation']\n",
    "        rr, cc = polygon(r=polygon_idx[:, 0], c=polygon_idx[:, 1], shape=image.shape)\n",
    "        image[rr, cc] = annotations_dict[idx][0]['category_id']\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_merged_mask(annotations_dict: dict, original_mask_path: str):\n",
    "    '''\n",
    "    input:\n",
    "        annotations_dict [dict] -- this is the output of the get_annotations() function\n",
    "        original_mask_path [str] -- path to the original mask that corresponds to the data in the annotations_dict\n",
    "    function:\n",
    "        merges the original_mask and with the data in the annotations_dict to create a new mask\n",
    "    return:\n",
    "        returns the combined mask, which contains all the classes\n",
    "    interactions:    \n",
    "    '''\n",
    "    # get the number of unique categories\n",
    "    unique_categories = [annotations_dict[idx][0]['category_id'] for idx in annotations_dict.keys()]\n",
    "    \n",
    "    # ADD SOME CODE TO WHERE FOR EACH UNIQUE CATEGORY A COLOR IS ASSIGNED -- TO BE COMPLETED -- NOT NECESSARY RIGHT NOW\n",
    "    \n",
    "    # create an empty image\n",
    "    image = cv2.imread(original_mask_path)\n",
    "    \n",
    "    for idx in annotations_dict.keys():\n",
    "        polygon_idx = annotations_dict[idx][1]['segmentation']\n",
    "        rr, cc = polygon(r=polygon_idx[:, 0], c=polygon_idx[:, 1], shape=image.shape)\n",
    "        image[rr, cc, :] = [255,255,0]\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_mask_dataset(data_dir: str):\n",
    "    \n",
    "    # get all the json filenames \n",
    "    json_filenames = glob(os.path.join(data_dir, '**/*.json'), recursive=True)\n",
    "    \n",
    "    # create lambda function to take json_filepath and creates a path pointing to labels directory \n",
    "    get_mask_save_name = lambda x, name: os.path.join(os.path.split(x)[0], 'labels/'+name+'_binary.png')\n",
    "    \n",
    "    for file in tqdm(json_filenames):\n",
    "#         print(file)\n",
    "        # open the json file\n",
    "        json_dict = open_json(path_to_file=file)\n",
    "        # loop through the json_dict looking at each image in the dictionary \n",
    "        for img in range(1, get_num_images(json_dict=json_dict)):\n",
    "            # get the current image filename\n",
    "            img_filename = get_image_filename(json_dict=json_dict, image_id=img)\n",
    "            # get the annotations for the current image\n",
    "            current_annotations = get_annotations(json_dict=json_dict, image_id=img+1)\n",
    "            # get the image sizes for the current image\n",
    "            row, col = get_image_size(json_dict=json_dict, image_id=img)\n",
    "            current_binary_mask = create_binary_mask(annotations_dict=current_annotations, image_size=(row, col))\n",
    "            plt.imsave(fname=get_mask_save_name(file, img_filename), arr=current_binary_mask)\n",
    "            \n",
    "    \n",
    "    print('[info] -- finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_merged_mask_dataset(data_dir: str):\n",
    "    \n",
    "    # get all the json filenames \n",
    "    json_filenames = glob(os.path.join(data_dir, '**/*.json'), recursive=True)\n",
    "    \n",
    "    # create lambda function to take json_filepath and creates a path pointing to labels directory \n",
    "    get_mask_save_name = lambda x, name: os.path.join(os.path.split(x)[0], 'labels/'+name+'_merged.png')\n",
    "    # create a lambda function to return the path of the original mask\n",
    "    original_mask_path = lambda x, name: os.path.join(os.path.split(x)[0], 'labels/'+name+'.png')\n",
    "    \n",
    "    for file in tqdm(json_filenames):\n",
    "#         print(file)\n",
    "        # open the json file\n",
    "        json_dict = open_json(path_to_file=file)\n",
    "        # loop through the json_dict looking at each image in the dictionary \n",
    "        for img in range(0, get_num_images(json_dict=json_dict)):\n",
    "            # get the current image filename\n",
    "            img_filename = get_image_filename(json_dict=json_dict, image_id=img)\n",
    "            # get the annotations for the current image\n",
    "            current_annotations = get_annotations(json_dict=json_dict, image_id=img+1)\n",
    "            # get the image sizes for the current image\n",
    "            row, col = get_image_size(json_dict=json_dict, image_id=img)\n",
    "            current_merged_mask = create_merged_mask(annotations_dict=current_annotations, original_mask_path=original_mask_path(file, img_filename))\n",
    "            plt.imsave(fname=get_mask_save_name(file, img_filename), arr=current_merged_mask)\n",
    "            \n",
    "    \n",
    "    print('[info] -- finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:43<00:00,  7.18s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] -- finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:42<00:00,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] -- finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# json data path\n",
    "data_dir = 'E:\\\\Datasets\\\\uavid_v1.5_official_release\\\\uavid_v1.5_official_release\\\\uavid_train'\n",
    "\n",
    "# run binary\n",
    "create_binary_mask_dataset(data_dir)\n",
    "# run merged\n",
    "create_merged_mask_dataset(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### END -- WORKING PIPELINE -- Shehan Perera"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
